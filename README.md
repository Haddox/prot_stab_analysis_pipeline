# Computational pipeline for analyzing data from the high-throughput protein-stability assay

This directory contains a computational pipeline for analyzing data from the high-throughput protein-stability assay from [Rocklin et al, 2017, Science](https://doi.org/10.1126/science.aan0693).

## How to run the pipeline

The pipeline is in the form of a series of `Python` scripts that are contained in the directory called `scripts/`. The entire pipeline can be run by calling the script `compute_ec50_values_from_deep_sequencing_data.py` with the appropriate command-line arguments, which are described below:

* `--designed_sequences_file` : the path to a CSV file giving the name and protein sequence for each input design. See [here](data/Rocklin_2017_Science/designed_protein_sequences.csv) for an example. In this file, each row specifies a design and each column specifies information about that design. This file must have the following columns:
    * `name` : a unique name for the design
    * `protein_sequence` : the protein sequence of the design

* `--fastq_dir` : a path to a directory that has the deep-sequencing data in the form of unassembled paired-end FASTQ files for all samples in the experiment.

* `--experimental_summary_file` : the path to a CSV file with a variety of metadata for each sample in the experiment, where samples are rows and columns are different pieces of metadata. See [here](data/Rocklin_2017_Science/experimental_summary.csv) for an example. This file is based on the `experiments.csv` file from the Rocklin et al. study, but contains come additional columns, and is also missing certain columns that will be added in later by the analysis code. The columns must include:
    * `experiment_id` : a unique ID for the entire experiment (**need to decide if I want to use this somehow**)
    * `protease_type` : the protease associated with the sample (e.g., "trypsin" or "chymotrypsin")
    * `selection_strength` : the index of the selection step associated with the sample, following the indexing scheme used in the Rocklin et al. study. The standard range of these values is normally: 0-6, where "0" corresponds to the naive library that has not been exposed to protease and "6" corresponds to the library that has been challenged with the highest concentration of protease.
    * `conc_factor` : the fold-change in protease concentration between selection steps, i.e., when `selection_strength` is incrimented by a value of one. A value of 3 would indicate that the protease concentration is increased by 3 fold between selection steps.
    * `parent` : the value of `selection_strength` for the sample that serves as the input library for the given selection. A value of 0 would indicate that the 
    * `fastq_id` : a string that is common to all FASTQ files for a given sample ***and*** is unique to those files. The code will search within the directory specified by `--fastq_dir` for all FASTQ files that contain this string in their name, aggregating the data among all matches. Thus, strings that are not unique to a particular dataset will result in "cross contamination" between datasets. Be careful when using numbers. For instance, the string "test1" would find not only FASTQ files with "test1" in their name, but also FASTQ files with "test10" in their name. Using a string like "test1\_" could be used to get around this problem.
    * `parent_expression`: the fraction of cells (events) passing the selection threshold in the given library before proteolysis, according to the sorting instrument.
    * `fraction_collected`: the fraction of cells (events) passing the selection threshold in the given library after proteolysis, according to the sorting instrument
    * `cells_collected`: the total number of cells (events) collected during the given selection, according to the sorting instrument

* `--pare_path` : a path to the program `PEAR`

* `--output_dir` : a path to an output directory where all the results will be stored. This directory will be created if it does not already exist


## Output of the pipeline

All results are stored in the directory specified by the input command `--output_dir`. Within this directory, there are multiple subdirectories that contain the results:

* `log.log` : a log file (currently, this file is not actually generated; I still need to implement this)

* `paired_FASTQ_files/` : this directory contains assembled FASTQ files and associated log files generated by `PARE`:
    * for each sample and for each pair of unassembled FASTQ files associated with that sample, a FASTQ of the assembled paired-end reads. The assembled FASTQ files are named according to the format: `{protease_type}_{selection_strength}-{n}.fastq`, where `protease_type` and `selection_strength` are derived from the corresponding entries in the input file specified by the command `--experimental_summary_file`, and where `n` corresponds to the index of the assembled pair of FASTQ files, indexed starting at one. This index is necessary since some samples may be associated with more than one pair of FASTQ files.

* `counts/` : this directory contains counts files, including:
    * for each sample, a file giving counts of all unique protein sequences observed in the deep-sequencing data. These files are named according to the format: `{protease_type}_{selection_strength}_counts.csv`.
    * for each protease, a file giving the counts aggregated across all samples that are associated with that protease. This file only includes counts for proteins that match one of the input designs included in the file specified by the input command `--designed_sequences_file` ***and*** have more than one counts in the naive library (selection index = 0). These files are named according to the format: `{protease_type}.counts`.
    
* `ec50_values/` : this directory contains a varity of output files, including:
    * `experiments.csv` : a file that serves as input into the script for computing EC50 values. This file is identical to the `experiments.csv` file described in the Rocklin et al. study.
    * for each protease, a file giving the aggregated counts across all samples that are associated with that protase. These files are the same as the ones in `counts/`, copied over for the purpose of inferring EC50s (the current script for inferring EC50s requires that all input is in the same directory; this should be changed in the future).
    * for each protease, a file giving the EC50 values and other metadata called `{protease}.sel_k0.8.erf.5e-7.0.0001.3cycles.fulloutput`. This file is in the same form as the `.fulloutput` files from the Rocklin et al. study. See [here](data/original_Rocklin_EC50_values/rd4_chymo.sel_k0.8.erf.5e-7.0.0001.3cycles.fulloutput) for an example.


## An example analysis

I provide an example of how to execute this pipeline in the `Jupyter` notebook called `analysis_code.ipynb`. In this notebook, I reproduce the entire analysis from the Rocklin et al. study, starting from the deep-sequencing data. Most of the input data for the analysis is stored in the directory called `data/`. However, the input FASTQ files are stored in a separate location on TACC.

I test that the results of my pipeline match the results from the Rocklin et al. study. Specifically, I have uploaded the following original data from the supplemental information of the Rocklin et al. study:
    * for each protease, a file giving protein counts generated from the raw deep-sequencing data. These files are stored in the directory `data/original_Rocklin_counts/` and are called `rd4_chymo.counts` and `rd4_tryp.counts` for chymotrypsin and trypsin, respectively.
    * for each protease, a file giving EC50 values (and other related metadata) for each protein design. These files are stored in the directory `data/original_Rocklin_EC50_values/` and are called `rd4_chymo.sel_k0.8.erf.5e-7.0.0001.3cycles.fulloutput` and `rd4_tryp.sel_k0.8.erf.5e-7.0.0001.3cycles.fulloutput` for chymotrypsin and trypsin, respectively.


## To do

* Set up a system for logging progress of the script
* Set up a `conda` environment that is completely self contained
    * currently, there is a problem with importing `pymc3` as installed by `conda`
* Make it so that don't need to copy over counts


## Summary of `Python` scripts in the pipeline

All of the code for the pipeline is in the directory called `scripts/`. Here are descriptions of each of the scripts in the directory.

* `compute_ec50_values_from_deep_sequencing_data.py`: the main script that performs the entire analysis. The below scripts are all dependencies for this script.
* `deep_seq_utils.py`: a custom script with `Python` functions for analyzing deep-sequencing data.
* `fit_all_ec50_data.py`: a script from Rocklin et al. that is used to fit EC50 values.
* `protease_sequencing_model.py` and `utility.py`: are both scripts from Rocklin et al. that are imported as modules for computing EC50 values.
* 





### `compute_ec50_values_from_deep_sequencing_data.py`

Compute EC50 values from deep-sequencing data. This module serves as a wrapper for the modules listed below.

* Outputs:
    * Assembled FASTQ files for each sample
    * Counts files for each sample, one giving all counts of all proteins, the other only giving counts for the input designs
    * EC50 values for each sample

### `assemble_and_align_reads.py`

Assemble paired-end deep-sequencing reads in the form of FASTQ files and then align the reads to a set of input sequences

* Inputs:
    * deep-sequencing data
    * a file giving the DNA and protein sequence for each input design for a given round of designs
    * a path to an output directory where the results will be stored

* Dependencies:
    * `PEAR`
    * `deep_seq_utils.py`: a custom `Python` script

* Outputs:
    * assembled paired-end reads in the form of FASTQ files for each sample
    * counts files with the number of times each protein was observed in each sample:
        * one file with counts for *all* sequences that were observed, even if they do not match a starting design
        * one file with counts for *only* sequences that match a starting design

### `summarize_alignments.py`

Make plots summarizing the alignments, including plots showing:
    * sequencing depth
    * number of sequences thrown out during the alignment
    * etc.

### `compute_ec50_values.py`

Compute ec50 values for a given experiment

* Inputs:
    * `experiments.csv` file

* Dependencies:
    * scripts from Rocklin et al., 2017, Science
    * `Python` modules

* Output:
    * EC50 values

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code that reproduces the complete analysis from Rocklin et al., 2017, Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import `Python` modules\n",
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "data_dir = 'data/Rocklin_2017_Science/'\n",
    "designed_sequences_file = os.path.join(data_dir, 'designed_protein_sequences.csv')\n",
    "experimental_summary_file = os.path.join(data_dir, 'experimental_summary.csv')\n",
    "fastq_dir = '/work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/'\n",
    "pear_path = '/home/05402/haddox/software/pear/bin/pear'\n",
    "output_dir = 'results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making the directory: results/\n",
      "Making the directory: results/paired_FASTQ_files\n",
      "Making the directory: results/counts\n",
      "Making the directory: results/ec50_values\n",
      "\n",
      "Aggergating paired-end FASTQ files for the trypsin-treated sample and for selection index 0\n",
      "Here is a list of R1 files: /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe1_S1_R1_001.fastq\n",
      "Here is a list of R2 files: /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe1_S1_R1_001.fastq\n",
      "\n",
      "Assembling the files /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe1_S1_R1_001.fastq and /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe1_S1_R2_001.fastq, outputting the assembled reads to a file called results/paired_FASTQ_files/trypsin_0-1.assembled.fastq\n",
      "\n",
      "Using PARE to assembling the files: /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe1_S1_R1_001.fastq and /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe1_S1_R2_001.fastq\n",
      "Using the command: /home/05402/haddox/software/pear/bin/pear -f /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe1_S1_R1_001.fastq -r /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe1_S1_R2_001.fastq -o results/paired_FASTQ_files/trypsin_0-1 -j 20\n",
      "Storing the results in an assembled FASTQ file called: results/paired_FASTQ_files/trypsin_0-1.assembled.fastq\n",
      "Logging the results of the run in a file called: results/paired_FASTQ_files/trypsin_0-1.log\n",
      "\n",
      "Aggergating paired-end FASTQ files for the trypsin-treated sample and for selection index 1\n",
      "Here is a list of R1 files: /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe3_S3_R1_001.fastq\n",
      "Here is a list of R2 files: /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe3_S3_R1_001.fastq\n",
      "\n",
      "Assembling the files /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe3_S3_R1_001.fastq and /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe3_S3_R2_001.fastq, outputting the assembled reads to a file called results/paired_FASTQ_files/trypsin_1-1.assembled.fastq\n",
      "\n",
      "Using PARE to assembling the files: /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe3_S3_R1_001.fastq and /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe3_S3_R2_001.fastq\n",
      "Using the command: /home/05402/haddox/software/pear/bin/pear -f /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe3_S3_R1_001.fastq -r /work/05402/haddox/jupyter/sd2e-community/archive/ingest/Q0/sd2.biofab.upload/Rocklin_ProtStab/gabe3_S3_R2_001.fastq -o results/paired_FASTQ_files/trypsin_1-1 -j 20\n",
      "Storing the results in an assembled FASTQ file called: results/paired_FASTQ_files/trypsin_1-1.assembled.fastq\n",
      "Logging the results of the run in a file called: results/paired_FASTQ_files/trypsin_1-1.log\n"
     ]
    }
   ],
   "source": [
    "# Write the command to carry everything out\n",
    "cmd = ' '.join([\n",
    "    'python',\n",
    "    'scripts/compute_ec50_values_from_deep_sequencing_data.py',\n",
    "    '--designed_sequences_file {0}'.format(designed_sequences_file),\n",
    "    '--experimental_summary_file {0}'.format(experimental_summary_file),\n",
    "    '--fastq_dir {0}'.format(fastq_dir),\n",
    "    '--pear_path {0}'.format(pear_path),\n",
    "    '--output_dir {0}'.format(output_dir)\n",
    "])\n",
    "\n",
    "! {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure the protein counts generated by the pipeline match the original protein counts reported by the Rocklin et al. study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in names and sequences of all input designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "designed_seqs_df = pandas.read_csv(designed_sequences_file)\n",
    "designed_seqs_df.set_index('name', inplace=True)\n",
    "designed_seqs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in counts from the above pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proteases = ['chymotrypsin', 'trypsin']\n",
    "counts_dfs = {\n",
    "    'pipeline' : {},\n",
    "    'original' : {}\n",
    "}\n",
    "counts_dir = os.path.join(output_dir, 'counts/')\n",
    "\n",
    "for protease in proteases:\n",
    "    \n",
    "    # Read counts into dataframe\n",
    "    df = pandas.read_csv(os.path.join(counts_dir, '{0}.counts'.format(protease)), sep=' ')\n",
    "    df.set_index('name', inplace=True)\n",
    "    print(\"Number of sequences for {0} with zero starting counts : {1}\".format(\n",
    "        protease,\n",
    "        sum(df['counts0'] == 0)\n",
    "    ))    \n",
    "    counts_dfs['pipeline'][protease] = df\n",
    "    \n",
    "counts_dfs['pipeline']['trypsin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in counts from the initial study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the counts from the original study\n",
    "for protease in proteases:\n",
    "    \n",
    "    # Read counts into dataframe\n",
    "    if protease == 'chymotrypsin':\n",
    "        df = pandas.read_csv('data/original_Rocklin_counts/rd4_chymo.counts', sep=' ')\n",
    "    elif protease == 'trypsin':\n",
    "        df = pandas.read_csv('data/original_Rocklin_counts/rd4_tryp.counts', sep=' ')\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    df.set_index('name', inplace=True)\n",
    "    print(\"Number of sequences for {0} with zero starting counts : {1}\".format(\n",
    "        protease,\n",
    "        sum(df['counts0'] == 0)\n",
    "    ))\n",
    "    \n",
    "    counts_dfs['original'][protease] = df\n",
    "    \n",
    "counts_dfs['original']['chymotrypsin']\n",
    "# counts_dfs['original']['trypsin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of sequences in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of sequence names in each dataset\n",
    "original_trypsin_seqs = list(counts_dfs['original']['trypsin'].index.values)\n",
    "pipeline_trypsin_seqs = list(counts_dfs['pipeline']['trypsin'].index.values)\n",
    "original_chymotrypsin_seqs = list(counts_dfs['original']['chymotrypsin'].index.values)\n",
    "pipeline_chymotrypsin_seqs = list(counts_dfs['pipeline']['chymotrypsin'].index.values)\n",
    "input_seqs = designed_seqs_df.index.values\n",
    "\n",
    "# Check that all sequences are unique\n",
    "for seqs in [\n",
    "    original_trypsin_seqs, pipeline_trypsin_seqs, original_chymotrypsin_seqs,\n",
    "    pipeline_chymotrypsin_seqs, input_seqs\n",
    "]:\n",
    "    assert(len(seqs) == len(set(seqs)))\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of input sequences is: {0}\".format(len(input_seqs)))\n",
    "print(\"Number of sequences with counts from the original study for the two proteases is: {0} and {1}\".format(\n",
    "    len(original_trypsin_seqs), len(original_chymotrypsin_seqs)\n",
    "))\n",
    "print(\"Number of sequences with counts from the pipeline for the two proteases is: {0} and {1}\".format(\n",
    "    len(pipeline_trypsin_seqs), len(pipeline_chymotrypsin_seqs)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantify the number of starting sequences with counts data in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set.intersection(set(input_seqs), set(original_trypsin_seqs))))\n",
    "print(len(set.intersection(set(input_seqs), set(pipeline_trypsin_seqs))))\n",
    "\n",
    "print(len(set.intersection(set(input_seqs), set(original_chymotrypsin_seqs))))\n",
    "print(len(set.intersection(set(input_seqs), set(pipeline_chymotrypsin_seqs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the number of input sequences and the number of sequences with counts data for\n",
    "# each protease and for the original Rocklin data vs. the pipeline data\n",
    "\n",
    "# Quantify the number of sequences that are overlapping between the two datasets\n",
    "overlapping_trypsin_seqs = set.intersection(set(original_trypsin_seqs), set(pipeline_trypsin_seqs))\n",
    "overlapping_chymotrypsin_seqs = set.intersection(set(original_chymotrypsin_seqs), set(pipeline_chymotrypsin_seqs))\n",
    "print(\"Number of sequences that overlap is:\")\n",
    "print(\"{0} for trypsin\".format(len(overlapping_trypsin_seqs)))\n",
    "print(\"{0} for chymotrypsin\".format(len(overlapping_chymotrypsin_seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for protease in proteases:\n",
    "    print(\"\\n------------------------------------------\")\n",
    "    print(\"Correlation plots for {0}\".format(protease))\n",
    "\n",
    "    # Define sequences that are shared between the two replicates\n",
    "    seqs1 = counts_dfs['original'][protease].index.values\n",
    "    seqs2 = counts_dfs['pipeline'][protease].index.values\n",
    "    shared_seqs = set.intersection(set(seqs1), set(seqs2))\n",
    "    print(\"Number of overlapping sequences is: {0}\".format(len(shared_seqs)))\n",
    "\n",
    "    x = counts_dfs['original'][protease].loc[shared_seqs]['counts0']\n",
    "    y = counts_dfs['pipeline'][protease].loc[shared_seqs]['counts0']\n",
    "    g = sns.jointplot(x=x, y=y)\n",
    "\n",
    "    # Make the plot square with the same ranges, add title, and fix axis labels\n",
    "    max_freq = max(x + y)\n",
    "    g.set_axis_labels(xlabel='original', ylabel='pipeline')\n",
    "\n",
    "    # Add text with correlation coefficient to plots\n",
    "    (r,p) = scipy.stats.pearsonr(x, y)\n",
    "    print('R = {0}'.format(r))\n",
    "    #plt.text(0.05, 0.75, '$R$ = {0}'.format(round(r, 2)), transform=ax.transAxes)\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find sequences that are present in the original data, but absent in data from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dfs['original'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_trypsin_seqs = set(original_trypsin_seqs).difference(set(pipeline_trypsin_seqs))\n",
    "counts_dfs['original']['trypsin'].loc[missing_trypsin_seqs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cells are for testing parts of the script in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import `Python` modules\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the designed sequences\n",
    "designed_seqs_df = pandas.read_csv(designed_sequences_file)\n",
    "designed_seqs_df.set_index('protein_sequence', inplace=True)\n",
    "\n",
    "# Read in data from the experiments summary file and get a list of\n",
    "# unique proteases and unique selection indices\n",
    "summary_df = pandas.read_csv(experimental_summary_file)\n",
    "proteases = set(summary_df['protease_type'])\n",
    "selection_indices = set(summary_df['selection_strength'])\n",
    "print(proteases)\n",
    "print(selection_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each sample in the experimental summary dataframe and compile\n",
    "# a list of FASTQ files for each sample\n",
    "FASTQ_files = {}\n",
    "for (i, row) in summary_df.iterrows():\n",
    "\n",
    "    # Get sample metadata\n",
    "    protease_type = row['protease_type']\n",
    "    selection_index = row['selection_strength']\n",
    "    experiment_name = '{0}_{1}'.format(protease_type, selection_index)\n",
    "    fastq_id = row['fastq_id'].replace('_', '-')\n",
    "\n",
    "    # Find R1 and R2 files and append them to a list\n",
    "    r1_files = glob.glob('{0}/{1}*_R1_*.fastq*'.format(fastq_dir, fastq_id))\n",
    "    r2_files = [f.replace('_R1_', '_R2_') for f in r1_files]\n",
    "    assert experiment_name not in FASTQ_files.keys(), \\\n",
    "        \"Duplicate experiment name: {0}\".format(experiment_name)\n",
    "    FASTQ_files[experiment_name] = list(zip(r1_files, r2_files))\n",
    "\n",
    "    # Make sure that each sample has the same number of R1 and R2 files, that\n",
    "    # there are more than one of each, and that the patterns \"_R1_\" and \"_R2_\"\n",
    "    # don't appear more than once\n",
    "    assert(len(r1_files) == len(r2_files))\n",
    "    if len(r1_files) == 0:\n",
    "        raise ValueError(\n",
    "            \"Failed to find FASTQ files for the fastq_id: {0}\".format(fastq_ID)\n",
    "        )\n",
    "    for (f1, f2) in zip(r1_files, r2_files):\n",
    "        assert f1.count('_R1_') == f2.count('_R2_') == 1, \\\n",
    "            \"The string '_R1_' or '_R2_' appear multiple times in file name\"\n",
    "        if not os.path.isfile(f2):\n",
    "            raise ValueError(\n",
    "                \"Failed to find a matching R2 file for: {0}\".format(f)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
